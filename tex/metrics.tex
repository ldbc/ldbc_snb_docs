\section{Performance metrics}\label{section:metrics}
\alert{ TODO} 
%\alert{ TODO - Renzo \\
%Here we need to describe the different metrics used to evaluate the performance
%of the systems.
%}
%
%\subsection{Response Time}
%
%Response Time (RT) is defined by RT = eT - sT where:
%\begin{itemize}
%    \item sT = time measured before the first byte of input data of the Transaction is sent by the Driver to the SUT; 
%    \item eT = time measured after the last byte of output data from the Transaction is received by the Driver from the SUT.
%\end{itemize}
%The resolution of the time stamps used for measuring Response Time is of at least \alert{XX} seconds.
%
%\subsection{Throughput}
%
%The throughput is measured as ''Operations per second at scale'' (i.e.  opsSI@100).
%The metric is calculated for a run that satisfies the minimum length and per
%query minimum execution count and query mix criteria.
%\alert{Describe here the criteria}
%Each completed operation counts as one operation. The metric is the count of successful operations
%divided by elapsed time in seconds.
%
%\subsection{Interactive Workload Metric}
%
%\alert{Need to elaborate on this. The current description in confluence is incomplete. Is this needed?}
%
%
%\subsection{Price/Performance Metric}
%\alert{We need to include the definition of a price/performance metric.}



